---
draft: false
date: '2023-06-06 14:36:28'
categories: Probability_and_Statistics
destination: 
excerpt: 
katex: true
obsidianUIMode: source
rating: ⭐⭐
tags:  
- Probability_and_Statistics 
title: "概率论第八章-参数估计"
share: true
updated: 2023-06-22 23:02:15
---

# 八 参数估计

> 统计学与概率论的区别就是归纳和演绎，前者通过样本推测总体的分布，而后者已知总体分布去研究样本。因此参数估计则是归纳的过程，参数估计有两种形式：**点估计**和**区间估计**（点估计和区间估计都是对于未知参数的估计，而**点估计给出的是一个参数可能的值**，**区间估计给出的是参数可能在的范围**）。

## 8.1 点估计

### 点估计的概念

- 参数估计

  - 设$X_1,X_2,...,X_n$是总体$X$的一个样本，其分布函数为$F(x;\theta),\theta\in\Theta$，其中$\theta$为未知参数，$\Theta$为参数空间，若统计量$g(X_1,...,X_n)$可作为$\theta$的一个估计，则称其为$\theta$的一个估计量，记为$\hat\theta$，即$\hat\theta=g(X_1,...,X_n)$
  - 注：分布函数$F(x;\theta)$也可用分布律（离散型）或密度函数（连续性）代替

- 点估计

  - 若$x_1,x_2,...,x_n$是样本的一个观测值，则称为$\theta$的估计值
  - 由于$g(x_1,x_2,...,x_n)$是实数域上的一个点，现用它来估计$\theta$，故称这种估计为**点估计**
  - 经典方法
    - 矩估计法
    - 极大似然估计法

### 点估计的方法

#### 矩估计

- 用样本矩作为总体同阶矩的估计，即用样本矩的函数去替换相应的总体矩函数
$$
E(\hat{X^k})=\frac1n\sum_{i=1}^nX_i^k
$$
也就是说，先根据具体分布条件，将 $E(X^k)$ 求出来，是一个关于未知参数 $\theta$ 的式子，然后将上式代入，解出 $\hat\theta$

#### 极大似然估计
- 思想：一件事情发生或不发生，如果试验一次就发生了，给我们的感觉就是发生的概率比不发生要大。

- 一般来说，事件$A$发生的概率与参数$\theta\in\Theta$有关，$\theta$取值不同，$P(A)$也不同，所以应该记事件$A$发生概率为$P(A|\theta)$，若$A$发生了，则认为此时的$\theta$值应是在$\Theta$中使得$P(A|\theta)$达到最大的那一个

- 对离散型随机变量$P\{X=a_k|\theta\}=P_{\theta}(a_k),k=1,2,...$，现有样本观察值$x_1,x_2,...,x_n$，如何用极大似然估计来估计$\theta$？

- 记$A=\{X_1=x_1,...,X_n=x_n\}$，则
$$
P(A|\theta)=P_{\theta}\{X_1=x_1,...,X_n=x_n\}=\prod_{i=1}^nP_{\theta}(x_i)
$$
根据极大似然思想， $\theta$ 的值应使得样本联合分布律 $\prod_{i=1}^nP_{\theta}(x_i)$ 达到最大。连续型同理。

+ 将样本的联合概率函数看成 $\theta$ 的函数，用 $L(\theta;x_1,...,x_n)$ 表示，简记为 $L(\theta)$ 
$$
L(\theta)=L(\theta;x_1,...,x_n)=p(x_1;\theta)p(x_2;\theta)...p(x_n;\theta)
$$
$L(\theta)$称为样本的**似然函数**。若统计量$\hat{\theta}=\hat{\theta}(x_1,...,x_n)$满足
$$
L(\hat{\theta})=\max_{\theta\in\Theta}L(\theta)
$$
则称$\hat{\theta}$是$\theta$的**最大似然估计**，简称**MLE（maximum likelihood estimate）.**

##### 求极大似然估计的步骤

- 做似然函数
$$
L(\theta)=L(x_1,...,x_n;\theta)=\prod_{i=1}^nf(x_i;\theta)
$$

- 做对数似然函数
$$
\ln L(\theta)=\ln L(x_1,...,x_n;\theta)=\sum_{i=1}^n\ln f(x_i;\theta)\ln L(\theta)=\ln L(x_1,...,x_n;\theta)=\sum_{i=1}^n\ln f(x_i;\theta)
$$

- 列方程：对参数向量求偏导，令其为 0
$$
\frac{d[\ln L(\theta)]}{d\theta}=0
$$
若有解，则解就是$\hat\theta_{MLE}(X_1,...,X_n)$

<!--Upload failed, remote server returned an error: Imgur is temporarily over capacity. Please try again later.-->
![](private/08-Assets/Pasted%20image%2020230623150648.png)



#### 最小均方误差估计

在样本量一定时，评价一个点估计好坏的度量指标可使用估计值$\hat{\theta}$与参数真值$\theta$的距离函数，最常用的是距离平方，由于$\hat{\theta}$具有随机性，对该函数求期望即得**均方误差**：
$$
\begin{align}
MSE(\hat{\theta})&=E(\hat{\theta}-\theta)^2\\
&=E[(\hat{\theta}-E\hat{\theta})+(E\hat{\theta}-\theta)]^2\\
&=E(\hat{\theta}-E\hat{\theta})^2+(E\hat{\theta}-\theta)^2+\underbrace{2E[(\hat{\theta}-E\hat{\theta})(E\hat{\theta}-\theta)]}_{E(\hat{\theta}-E\hat{\theta})=0}\\
&=\underbrace{Var(\hat{\theta})}_{点估计的方差}+\underbrace{(E\hat{\theta}-\theta)^2}_{偏差的平方}
\end{align}
$$
其中，**如果$\hat{\theta}$是$\theta$的无偏估计，则$MSE(\hat{\theta})=Var(\hat{\theta})$，此时用均方误差评价点估计与用方差是完全一样的**。如果如果$\hat{\theta}$不是$\theta$的无偏估计，就要看其均方误差$MSE(\hat{\theta})$，即不仅要看其方差大小，还要看其偏差大小。

**定义**设有样本$x_1,...,x_n$，对待估参数$\theta$，设有一个估计类，如果对该估计类中另外任意一个$\theta$的估计$\widetilde{\theta}$，在参数空间$\Theta$上都有$MSE_\theta(\hat{\theta})\leq MSE_\theta(\widetilde{\theta})$，称$\hat{\theta}(x_1,...,x_n)$是该估计类中$\theta$的一致最小均方误差估计。

#### 最小方差无偏估计

**定义**设$\hat{\theta}$是$\theta$的一个无偏估计，如果对另外任意一个$\theta$的无偏估计$\widetilde{\theta}$，在参数空间$\Theta=\{\theta\}$上都有$Var_{\theta}(\hat{\theta})\leq Var_{\theta}(\widetilde{\theta})$，则称$\hat{\theta}$是$\theta$的一致最小方差无偏估计，简记为**UMVUE**。

**判断准则**设$\hat{\theta}=\hat{\theta}(x_1,...,x_n)$是$\theta$的一个无偏估计，$Var(\hat{\theta})<+\infty$.如果对任意一个满足$E(\varphi(x_1,...,x_n))=0$的$\varphi$，都有
$$
Cov_\theta(\hat{\theta},\varphi)=0,\quad\forall\theta\in\Theta,
$$
则$\hat{\theta}$是$\theta$的UMVUE.

#### 贝叶斯估计

区别于频率学派，在统计推断中贝叶斯用到了三种信息：**总体信息、样本信息和先验信息**（频率学派只用了前两种），其中：

* 总体信息：总体信息即总体分布或总体所属分布族提供的信息，如，若已知总体是正态分布，则可以知道很多信息；
* 样本信息：样本信息即抽取样本所得观测值提供的信息，如，在有了样本观测值后，可以根据它知道总体的一些特征数；
* 先验信息：若把抽取样本看作做一次试验，则样本信息就是试验中得到的信息，如，在一次抽样后，这第一次的抽样就是先验信息。先验信息来源于经验和历史资料。

**回顾贝叶斯公式**：设$\{B_1, B_2, ...B_n\}$是样本空间的一个分割，$A$为$\Omega$中的一个事件，$P(B_i)>0$，$i=1,2,...,n$，$P(A)>0$，则
$$
P(B_i|A)=\frac{P(A|B_i)P(B_i)}{\sum_{j=1}^{n}P(A|B_j)P(B_j)}
$$
##### 贝叶斯密度函数形式

* 在参数$\theta$分布已知（已假设）的情况下，$p(x|\theta)$表示随机变量$\theta$取某个给定值时总体的**条件概率函数**，（参考$P(A|B)$）；

* 任一未知量$\theta$都可以看作随机变量，可用一个概率分布去描述，这个分布成为**先验分布**，该先验分布$\pi(\theta)$，（参考$P(B)$）；

* 贝叶斯的观点，样本$X=(x_1,...,x_n)$的产生需分两步：

* 从先验分布$\pi(\theta)$产生一个样本$\theta_0$；
* 从$p(X|\theta_0)$中产生一组样本。

此时，样本$X=(x_1,...,x_n)$的**联合条件概率函数**（参考$\sum_{j=1}^{n}P(A|B_j)$）为
$$
p(X|\theta_0)=p(x_1,...,x_n|\theta_0)=\prod^{n}_{i=1}p(x_i|\theta_0)
$$

* 因为$\theta_0$未知，是从先验分布$\pi(\theta)$中产生的，所以需要考虑它的发生概率，样本$X$和参数$\theta$的**联合分布**（参考$\sum_{j=1}^{n}P(A|B_j)P(B_j)$）为
$$
h(X,\theta)=p(X|\theta)\pi(\theta)
$$

* 因为目的是对$\theta$进行推断，所以在有样本观测值$X=(x_1,...,x_n)$之后，可依据$h(X,\theta)$对$\theta$作出推断，按照乘法公式（参考1.5.2节），$h(X,\theta)$可分解为
$$
h(X,\theta)=\pi(\theta|X)m(X)
$$
其中，$m(X)$是$X$的边际概率函数，类比$\pi(\theta)$，
$$
m(X)=\int_\Theta h(X,\theta)d\theta=\int_\Theta p(X|\theta)\pi(\theta)d\theta
$$
所以可通过条件概率$\pi(\theta|X)$推断$\theta$的分布
$$
\pi(\theta|X)=\frac{h(X,\theta)}{m(X)}=\frac{p(X|\theta)\pi(\theta)}{\int_{\Theta}p(X|\theta)\pi(\theta)d\theta}
$$
该分布成为$\theta$的**后验分布**。**它其实是利用总体和样本对先验分布$\pi(\theta)$调整的结果，比$\pi(\theta)$更接近$\theta$的实际情况（机器学习里的贝叶斯模型就是基于这样的原理）**。

## 8.2 估计量的评选标准

### 无偏性

- 设$\hat\theta=\hat\theta(X_1,...,X_n)$为$\theta$的估计量，若$E\hat\theta=\theta$，则称$\hat\theta$为$\theta$的无偏估计量

实际意义就是说，用估计量$\hat\theta$来对未知参数$\theta$进行估计，有时会高于$\theta$，有时会低于$\theta$，但平均下来还是相等的，也就是**没有系统误差**

- 一些性质

- $X_1,X_2,...,X_n$是来自总体的一个样本，那么$k$阶样本原点矩$A_k$是总体样本原点矩$\mu_k$ （如果存在的话）的无偏估计，即
$$
E(A_k)=E[\frac1n\sum_{i=1}^nX_i^k]
$$

- 总体 $X$ 的方差 $\sigma^2$ 存在且有限， $X_1,X_2,...,X_n$ 是来自总体的一个样本，则**修正样本方差** $S^2$ 是总体方差 $\sigma^2$ 的**无偏估计**
$$
\begin{align*}
S^{*2}&= \frac1{n-1}\sum_{i=1}^n(X_i-\bar X)^2=\frac1{n-1}\sum_{i=1}^nX_i^2-\frac n{n-1}(\bar X)^2\\
E(S^{*2})&= \frac1{n-1}\sum_{i=1}^nE(X_i^2)-\frac n{n-1}E(\bar X)^2\\
&= \frac1{n-1}\sum_{i=1}^n(\sigma^2+\mu^2)-\frac n{n-1}(\frac{\sigma^2}{n}+\mu^2)=\sigma^2
\end{align*}
$$
同时可见，样本中心二阶矩$S^{*2}=\frac1n\sum_{i=1}^n(X_i-\bar X)^2$不是方差$\sigma^2$的无偏估计，

但有$E(S^{*2})=\frac{n-1}{n}\sigma^2\rightarrow\sigma^2$，我们称$S^{*2}$为$\sigma^2$的**渐进无偏估计**

### 有效性

- 设$\hat\theta_i,i=1,2$分别是参数$\theta$的两个无偏估计即$E(\hat\theta_i)=\theta$，若$D(\hat\theta_1)<D(\hat\theta_2)$，则称$\hat\theta_1$比$\hat\theta_2$有效，也就是比较$E(\hat\theta_i-\theta)^2$（称为**均方误差**，记为$M(\hat\theta,\theta)=E(\hat\theta-\theta)^2$）

### 一致性

- 设$\hat\theta_n=\hat\theta(X_1,X_2,...,X_n)$是$\theta$的估计量，若$\ce{{\hat{\theta_n}}->[p]\theta}$，则称$\hat\theta_n$为$\theta$的一致估计量

### 相合性

根据格里纹科定理，随着样本量不断增大，经验分布函数逼近真实分布函数，即设$\theta\in\Theta$为未知参数，$\hat{\theta}_n=\hat{\theta}_n(x_1,...,x_n)$是$\theta$的一个估计量，$n$是样本容量，若对任何一个$\epsilon>0$，有
$$
\lim_{n\rightarrow\infty}P(|\hat{\theta}_n-\theta|\geq\epsilon)=0
$$
则称$\hat{\theta}_n$为参数$\theta$的相合估计。

**定理1**设$\hat{\theta}_n=\hat{\theta}_n(x_1,...,x_n)$是$\theta$的一个估计量，若
$$
\lim_{n\rightarrow\infty}E(\hat{\theta}_n)=\theta,\quad\lim_{n\rightarrow\infty}Var(\hat{\theta}_n)=0
$$
则$\hat{\theta}_n$是$\theta$的相合估计。

**定理2**若$\hat{\theta}_{n1},...,\hat{\theta}_{nk}$分别是$\theta_1,...,\theta_k$的相合估计，$\eta=g(\theta_1,...,\theta_k)$是$\theta_1,...,\theta_k$的连续函数，则$\hat{\eta}_n=g(\hat{\theta}_{n1},...,\hat{\theta}_{nk})$是$\eta$的相合估计。

> 矩估计一般都具有相合性：
> * 样本均值是总体均值的相合估计；
> * 样本标准差是总体标准差的相合估计；
> * 样本变异系数$s/\bar{x}$是总体变异系数的相合估计。

### 渐进正态性（MLE）

在很一般条件下，总体分布 $p(x;\theta)$ 中的 $\theta$ 的 MLE $\hat{\theta}_n$ 具有相合性和渐进正态性，即 $\hat{\theta}_n\sim AN(\theta,\frac{1}{nI(\theta)})$ ，其中 $n$ 为样本容量， $I(\theta)=\int_{-\infty}^{\infty}(\frac{\partial{lnp}}{\partial\theta})^2p(x;\theta)dx$ 为费希尔信息量。

### 充分性（UMVUE）
* 任一参数$\theta$的UMVUE不一定存在，若存在，则它一定是充分统计量的函数；
* 若$\theta$的某个无偏估计$\hat{\theta}$不是充分统计量$T=T(x_1,...,x_n)$的函数，则通过条件期望可以获得一个新的无偏估计$\widetilde{\theta}=E(\hat{\theta|T})$，且方差比原估计的方差要小；
* 考虑$\theta$的估计时，只需要在其充分统计量的函数中寻找即可，该说法对所有统计推断都是正确的，这便是充分性原则。

## 8.3 区间估计

前面是用一个点来估计未知参数，那么现在尝试构造一个区间$(\hat\theta_1,\hat\theta_2)$来估计参数$\theta$的范围

### 区间估计的相关概念

- 设$\theta$是总体$X$的未知参数，$X_1,...,X_n$是来自总体$X$的样本，若对给定值$\alpha\in(0,1)$，存在两个统计量$\hat\theta_1(X_1,...,X_n),\hat\theta_2(X_1,...,X_n)$，使得
$$
P(\hat\theta_1<\theta<\hat\theta_2)=1-\alpha
$$
则称区间 $(\hat\theta_1,\hat\theta_2)$ ，是 $\theta$ 的**置信度**为 $1-\alpha$ 的**置信区间**， $\hat\theta_1,\hat\theta_2$ 为**置信下限**和**置信上限**，而 $\alpha$ 称**显著性水平**。

### 区间估计的方法

#### 枢轴量法

***Step 1***：设法构造一个样本和 $\theta$ 的函数 $G=G(x_1,...,x_n,\theta)$ 使得 $G$ 的分布不依赖于未知参数，称具有这种性质的 $G$ 为**枢轴量**。

***Step 2***：适当地选择两个常数c，d，使对给定的$\alpha\quad(0<\alpha<1)$，有
$$
P(c\leq G\leq d)=1-\alpha
$$
（在离散场合，将上式等号改为$\geq$）

***Step 3***：假如能将$c\leq G\leq d$进行不等式等价变形化为$\hat{\theta}_L\leq\theta\leq\hat{\theta}_U$，则有
$$
P_\theta(\hat{\theta}_L\leq\theta\leq\hat{\theta}_U)=1-\alpha
$$
表明$[\hat{\theta}_L,\hat{\theta}_U]$是$\theta$的$1-\alpha$同等置信区间。

> [!seealso]+ Note
>注：满足条件的c和d有很多，最终选择的目的是希望平均长度$E_\theta(\hat{\theta}_U)-\hat{\theta}_L$尽可能短，但在一些场合中很难做到这一点，因此可以选择c和d，使得两个尾部概率各为$\alpha/2$，即
>$$
>P_\theta(G<c)=P_\theta(G>d)=\alpha/2
>$$
>得到等尾置信区间。

> [!example]+
>例：设$x_1,...,x_n$是来自均匀总体$U(0,\theta)$的一个样本，试对设定的$\alpha\ (0<\alpha<1)$给出$\theta$的$1-\alpha$同等置信区间。
>
>解：三步法：
>
>* 已知$\theta$的最大似然估计为样本的最大次序统计量$x_{(n)}$，而$x_{(n)}/\theta$的密度函数为
> $$
> p(y;\theta)=ny^{n-1},\quad 0<y<1
> $$
> 它与参数$\theta$无关，故可取$x_{(n)}/\theta$作为枢轴量$G$。
>
>* 由于$x_{(n)}/\theta$的分布函数为$F(y)=y^n$，$0<y<1$，故$P(c\leq x_{(n)}/\theta\leq d=d^n-c^n)$，因此可以选择适当的c和d满足
> $$
> d^n-c^n=1-\alpha
> $$
>
>* 在$0\leq c<d\leq 1$及$d^n-c^n=1-\alpha$的条件下，当$d=1, c=\sqrt[n]{\alpha}$时，$E_\theta(\hat{\theta}_U)-\hat{\theta}_L$取最小值，所以$[x_{(n)},x_{(n)}/\sqrt[n]{\alpha}]$是$1-\alpha$置信区间

### 正态总体参数的区间估计

- 设 $X_1,...,X_n$ 独立同分布 $\sim N(\mu,\sigma^2)$ ，给定 $\alpha$ ，由观测值 $\xi_1,\cdots,\xi_n$ ，求出样本均值 $\mu$ 的 $1-\alpha$ 置信区间

#### $\mu$ 的估计

##### $\sigma^2$ 已知

由于$\mu$的点估计量为$\bar{X}$，且$\bar{X}～N(\mu,\frac{\delta^2}{n})$，构造
$$
U\overset{def}{=}\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}～N(0,1)
$$
则对于给定的置信度$1-\alpha$，由分位点的概念知，存在一个标准正态分布上的$\frac{\alpha}{2}$分位点$u_{\frac{\alpha}{2}}$，使得
$$
P\{|\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}|<u_{\frac{\alpha}{2}}\}=1-\alpha
$$
因为加了绝对值所以是$u_{\frac{\alpha}{2}}$，解得
$$
P\{\bar{X}-u_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}<\mu<\bar{X}+u_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}\}=1-\alpha
$$
所以$\mu$的置信度为$1-\alpha$的置信区间为
$$
(\bar{X}-u_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}，\bar{X}+u_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}})
$$

当然$\mu$的置信区间并不唯一
$$
\forall\theta,(\bar{X}-u_{\theta{\alpha}}\frac{\sigma}{\sqrt{n}}，\bar{X}+u_{(1-\theta){\alpha}}\frac{\sigma}{\sqrt{n}})
$$
都是$\mu$的$1-\alpha$置信区间，只是$\theta=\frac12$时区间长度最短

由上述过程可以总结出，求正态总体参数置信区间的解题步骤：
    - 构造样本的函数，要求**仅含待估参数且分布已知**——枢轴量
    - 令枢轴量落在分位点确定的区间中的概率为给定的置信度（$1-\alpha$）。要求**区间按几何对称或概率对称**
    - 解不等式得随机的置信区间
    - 由观测值及$\alpha$值查表计算得所求置信区间

##### $\sigma^2$ 未知

由
$$
T=\frac{\bar{X}-\mu}{S^{*}/\sqrt{n}}～t(n-1)
$$
从而有
$$
P\{|\frac{\bar{X}-\mu}{S^*/\sqrt{n}}|<t_{\frac{\alpha}{2}}(n-1)\}=1-\alpha
$$
解得
$$
P\{\bar{X}-t_{\frac{\alpha}{2}}(n-1)\frac{S^*}{\sqrt{n}}\leq\mu\leq \bar{X}+t_{\frac{\alpha}{2}}(n-1)\frac{S^*}{\sqrt{n}}\}=1-\alpha
$$
所以$\mu$的置信度为$1-\alpha$的置信区间为
$$
（\bar{X}-t_{\frac{\alpha}{2}}(n-1)\frac{S^*}{\sqrt{n}}，\bar{X}+t_{\frac{\alpha}{2}}(n-1)\frac{S^*}{\sqrt{n}}）
$$

#### $\sigma^{2}$ 的估计

##### $\mu$ 未知
引进
$$
\chi^2=\frac{(n-1)S^{*2}}{\sigma^2}\sim\chi^2(n-1)
$$
对于给定的置信度，可以有这样的构造
$$
\begin{align*}
P\{\chi^2<\chi^2_{1-\frac{\alpha}{2}}(n-1)\}=\frac{\alpha}{2}\\
P\{\chi^2>\chi^2_{\frac{\alpha}{2}}(n-1)\}=\frac{\alpha}{2}
\end{align*}
$$
于是有
$$
P\{\chi^2_{1-\frac{\alpha}{2}}(n-1)<\frac{(n-1)S^{*2}}{\sigma^2}<\chi^2_{\frac{\alpha}{2}}(n-1)\}=1-\alpha
$$
从而
$$
P\{\frac{(n-1)S^{*2}}{\chi^2_{\frac{\alpha}{2}}(n-1)}<\sigma^2<\frac{(n-1)S^{*2}}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}\}=1-\alpha
$$
所以$\sigma^2$的$1-\alpha$置信区间为
$$
\left(\frac{(n-1)S^{*2}}{\chi^2_{\frac{\alpha}{2}}(n-1)},\frac{(n-1)S^{*2}}{\chi^2_{1-\frac{\alpha}{2}}(n-1)}\right)
$$

##### $\mu$ 已知

引进 
$$
\chi^{2}=\sum\limits_{i=1}^n\left(\frac{\xi_i-\mu}{\sigma}\right)^2=\frac{1}{\sigma^2}\sum\limits_{i=1}^n(\xi_i-\mu)^2-\chi^2(n)
$$
作为枢轴变量:
$$
P\{ \chi_{1-\frac{\alpha}{2}}^{2}(n)\leqslant \frac{1}{	\sigma^{2}}\sum\limits_{i=1}^{n}(\xi_{i}-\mu)^{2} \leqslant \chi^{2}_{\frac\alpha2}(n)=1-\alpha \}
$$
区间估计为：
$$
\left[ \frac{\sum\limits_{i=1}^{n}(\xi_{i}-\mu)^{2}}{	\chi^{2}_{\frac\alpha2}\left(n\right)}, \frac{\sum\limits_{i=1}^{n}(\xi_{i}-\mu)^{2}}{	\chi^{2}_{1-\frac\alpha2}(n)} \right]
$$

### 两个正态总体均值差的置信区间：

设 $X_1,...,X_n$ 独立同分布 $\sim N(\mu_1,\sigma_1^2)$ ， $Y_1,...,Y_n$ 独立同分布 $\sim N(\mu_2,\sigma_2^2)$ ，两样本独立。给定置信度 $1-\alpha$ ，

#### 求 $\mu_1-\mu_2$ 的置信区间

##### $\sigma_1^2=\sigma_2^2=\sigma^2$ 未知
$$
T=\frac{\bar X-\bar Y-(\mu_1-\mu_2)}{S_w\sqrt{1/n_1+1/n_2}}\sim t(n_1-1+n_2-1)
$$
那么有
$$
P\{|T|<t_{\frac\alpha2}(n_1+n_2-2)\}=1-\alpha
$$
可解得$\mu_1-\mu_2$得置信区间
$$
\begin{align*}
(\bar X-\bar Y-t_{\frac\alpha2}(n_1+n_2-2)S_w\sqrt{1/n_1+1/n_2},\\ \bar X-\bar Y+t_{\frac\alpha2}(n_1+n_2-2)S_w\sqrt{1/n_1+1/n_2}),\\其中~~~
S_w^2=\frac{(n_1-1)S_1^{*2}+(n_2-1)S_2^{*2}}{n_1+n_2-2}
\end{align*}
$$

##### $\sigma_1,\sigma_2$ 已知

相当于是求$Z_i=X_i-Y_i\sim N(\mu_1-\mu_2,\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2})$，类似单个正态总体$\sigma^2$已知时求$\mu$的区间估计

#### 求 $\frac{\sigma_1^2}{\sigma_2^2}$ 的置信区间

##### $\mu_1,\mu_2$ 未知
引进
$$
F=\frac{S_1^{*2}/\sigma_1^2}{S_2^{*2}/\sigma_2^2}\sim F(n_1-1,n_2-1)
$$
根据$F$分布图像分位点可知

$$
P\{F_{1-\frac\alpha2}(n_1-1,n_2-1)<F<F_{\frac\alpha2}(n_1-1,n_2-1)\}=1-\alpha
$$
可解得$\frac{\sigma_1^2}{\sigma_2^2}$的置信区间为
$$
(\frac{{S_1^{*2}}/{S_2^{*2}}}{F_{\frac\alpha2}(n_1-1,n_2-1)},\ \ \frac{{S_1^{*2}}/{S_2^{*2}}}{F_{1-\frac\alpha2}(n_1-1,n_2-1)})
$$

##### $\mu_1,\mu_2$ 已知
引进
$$F=\frac{n_{2}\sigma_{2}^{2}}{n_{1}\sigma_{1}^{2}}.\frac{\sum_{i=1}^{n_{1}}\left(X_{i}-\mu_{1}\right)^{2}}{\sum_{j=1}^{n_{2}}\left(Y_{j}-\mu_{2}\right)^{2}}\sim F(n_{1},n_{2})$$
$$
P\{F_{1-\frac\alpha2}(n_1,n_2)<F<F_{\frac\alpha2}(n_1,n_2)\}=1-\alpha
$$
置信区间为：
$$
\left[ \frac{n_{2}}{n_{1}}.\frac{\sum_{i=1}^{n_{1}}\left(X_{i}-\mu_{1}\right)^{2}}{\sum_{j=1}^{n_{2}}\left(Y_{j}-\mu_{2}\right)^{2}} \cdot \frac{1}{F_{\frac\alpha2}(n_1,n_2)},\frac{n_{2}}{n_{1}}.\frac{\sum_{i=1}^{n_{1}}\left(X_{i}-\mu_{1}\right)^{2}}{\sum_{j=1}^{n_{2}}\left(Y_{j}-\mu_{2}\right)^{2}} \cdot \frac{1}{F_{1-\frac\alpha2}(n_1,n_2)} \right]
$$


